---
title: "Earthquakes"
author: "Samuel Richards"
output:
  pdf_document:
    keep_tex: TRUE
  html_document:
    toc: yes
    toc_float: yes
    code_folding: hide
    number_sections: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(leaflet)
library(leaflegend)
library(lubridate)
library(plotly)
library(caret)
library(scales)
library(brnn)
library(neuralnet)
library(RSNNS)
```

Data was queried using USGS Earthquake Catalog: https://earthquake.usgs.gov/earthquakes/search/ to select all recorded earthquakes of magnitude 4.5 and above with the following query parameters:

- latitude 35.4 - 41.2
- longitude 137.5 - 145.2
- Timeframe(UTC): 2011-03-11 00:00:00 - 1965-01-01 00:00:00

The data was stored locally in a .csv file named `earthquakes`.

The organization also has an package called `rcomcat` to query data directly into `R`, but its version was not compatible at the time of this thesis.

```{r}
#read the data and create a new variable to be able to select annual timepoints while preserving the original timestamp
earthquakes_full <- read.csv("data/earthquakes.csv") %>% 
  mutate(timestamp = ymd_hms(time)) %>% 
  arrange(timestamp) %>% 
  mutate(year = year(timestamp))


#subsets the data to include only the highest magnitude earthquake for each year (plus the most recent before the big one)
yearly <- earthquakes_full %>% group_by(year) %>% 
  slice_max(mag) %>% 
  distinct(year,.keep_all = T) %>% 
  rbind(earthquakes_full[3158,]) %>% 
  arrange(timestamp)

```

## Plot of Earthquakes

The highest magnitude earthquake each year from 1965 - 2011

```{r eval=FALSE, include=FALSE}
#Plot of the earthquakes

leaflet(yearly) %>% 
  addTiles() %>% 
  addCircleMarkers(lng = ~longitude,
                   lat = ~latitude,
                   radius = ~(exp(mag))^(1/3),
                   stroke = F,
                   fillOpacity = .5,
                   color = ~ifelse(yearly$mag > 9, "darkred", "darkblue"),
                   popup = ~as.character(paste0(place, "<br>",
                                                "<br><strong>Date and Time: </strong>", timestamp,
                                                "<br><strong>Magnitude: </strong>", mag)
                                         )
  )
```


## Data Preprocessing

```{r}
#Subset data to include observations from January 1, 1965 to the Greak Quake of March 11, 2011
earthquakes_subset <- earthquakes_full[which(earthquakes_full$time >= "1965-01-26T23:47:37.120Z" &                                                       earthquakes_full$time <= "2011-03-11T05:46:24.120Z"),]

#If I want to subset by the same geographic area as the book
#eq <- eq[which(eq$latitude > 37.72 & eq$latitude < 38.82 & eq$longitude > 141.87 & eq$longitude < 142.87),]

#Fine-tuning the geographic area of the model...
earthquakes_subset <- earthquakes_subset[which(earthquakes_subset$latitude > 35.72 &
                                               earthquakes_subset$latitude < 40.82 &
                                               earthquakes_subset$longitude > 139.37 &
                                               earthquakes_subset$longitude < 143.37),]

earthquakes_subset <- earthquakes_subset[-as.numeric(count(earthquakes_subset)),] #to omit the 9.1

#---data frame of magnitudes (rounded to .1) and relative frequencies
eq <- data.frame(table(round(earthquakes_subset$mag, 1)) ) %>% 
      rename(mag = Var1,
      freq = Freq)

eq$mag <- as.numeric(as.character(eq$mag)) #change to numeric rather than factors

eq$freq <- eq$freq/(2011-1965) #AVERAGE annual frequencies over the 46-year span


#creates a new variable representing the frequency of earthquakes of AT LEAST that magnitude
for(i in 1:as.numeric(count(eq))){
  eq$freqc[i] <- sum( eq$freq[c(i:as.numeric(count(eq)))] )
}

eq_log <- eq %>% mutate(freqc = log10(freqc)) #transforming to the log scale

# earthquakes <- gg
# earthquakes_log <- earthquakes %>% mutate(freqc = log10(freqc)) #transforming to the log scale
```


## Frequency of Earthquakes
Relative to Magnitude

```{r eval=FALSE, include=FALSE}
#---frequencies of each magnitude
ggplot(eq, aes(x = mag, y = freqc)) +
  geom_point(size = 4, shape = 17 ) +
    theme_minimal() +
    labs(x = "Magnitude",
       y = "Annual Frequency of At Least this Magnitude",
       title = "Annual Earthquake Frequency near Tohoku, Japan" ) +
  ylim(0,50)
  
#---frequencies on the logarithmic scale
ggplot(eq, aes(x = mag, y = freqc)) +
  geom_point(size = 4, shape = 17 ) +
  theme_minimal() +
  scale_y_log10(limits = c(.001,100)) +
  scale_x_log10(limits = c(4.5,10)) +
  labs(x = "Magnitude",
       y = "Annual Frequency of At Least this Magnitude",
       title = "Annual Earthquake Frequency near Tohoku, Japan - Logarithmic Scale" ) +
  stat_smooth(method = lm,
              formula = y ~ poly(x,1),
              fullrange = T)

#---frequencies on the logarithmic scale, 2nd order polynomial
ggplot(eq, aes(x = mag, y = freqc)) +
  geom_point(size = 4, shape = 17 ) +
  theme_minimal() +
  scale_y_log10(limits = c(.001,100)) +
  scale_x_log10(limits = c(4.5,10)) +
  labs(x = "Magnitude",
       y = "Annual Frequency of At Least this Magnitude",
       title = "Annual Earthquake Frequency near Tohoku, Japan - Logarithmic Scale",
       subtitle = "Linear Model with Second Order Polynomial") +
  stat_smooth(method = lm,
              formula = y ~ poly(x,2),
              fullrange = T)
```


## Linear models of the data

Calculation of the fit lines above.  

```{r eval=FALSE, include=FALSE}
#---modeling---
linear <- lm(data = eq_log, formula = freqc ~ mag)

# RESEARCH --- why does the model summary change when I write it this way, but not the prediction?
#linear <- lm(data = eq_log, formula = freqc ~ poly(mag,1))

summary(linear)
p <- predict(linear, newdata = data.frame(mag = 9.1))

1/10^p #undo log transform for final result
```
For completeness, this model shows that on average, for every 1.0 increase in magnitude, the lapsed time between earthquakes of *at least* that magnitude is expected to increase by $1/10^{-1.01971}$ = `r 1/10^-1.01971` years.

For a magnitude 9.1 earthquake, the expected frequency would be one every $1/10^{6.38365-1.01971(9.1)}$ = `1/10^p` years.


### Data table of polynomial orders and respective predictions:
```{r eval=FALSE, include=FALSE}
capacity <- 1:8
prediction <- NULL

for(i in capacity){
  lm <- lm(data = eq_log, formula = freqc ~ poly(mag,i))
  p <- predict(lm, newdata = data.frame(mag = 9.1))
  prediction[i] <- 1/10^p
}
data.frame(capacity,prediction)
```




## mlp

write mlp description stuff here...

```{r eval=FALSE, include=FALSE}
set.seed(4723)

#shuffle the data
df <- eq_log[sample(nrow(eq_log)), ]

#Extract 70% of data into train set and the remaining 30% in test set
train_test_split <- 0.7 * nrow(df)
train <- df[1:train_test_split,]
test <- df[(train_test_split+1): nrow(df),]

mlp <- neuralnet(freqc ~ mag,
                 stepmax = 1e+06,
                 data = train,
                 hidden = c(5,5))

#prediction for magnitude 9.1
p <- predict(mlp, newdata = data.frame(mag = 9.1))
1/10^p
```

Using this neural network model, the expected frequency of a magnitude 9.1 earthquake would be one every `1/10^p` years.


### plots for mlp

```{r eval=FALSE, include=FALSE}

#---actual test data---
actual_log_mlp <- eq_log %>% 
  mutate(type = "actual")
#  add_row(mag = addt, freqc = NA, type = "actual")

#---predicted data---
mdp <- seq(8,9.1, by = .1) #additional magnitude data points to add to prediction data

mlp_preds <- eq_log$mag %>% append(mdp) #append additional magnitudes to make predictions

predicted_log_mlp <- data.frame(mag = mlp_preds,
                               freqc = predict(mlp, newdata = data.frame(mag = mlp_preds)),
                               type = "predicted")

#---combine test and predictions for plot---
mlp_plot <- rbind(predicted_log_mlp,actual_log_mlp[,c(1,3,4)])

#---generate plot---
ggplot(mlp_plot, aes(x = mag, y = freqc, group = type, color = type)) +
  geom_line() +
  geom_point(size = 2, shape = 17 ) +
  theme_minimal() +
  labs(x = "Magnitude",
       y = "Annual Frequency of At Least this Magnitude",
       title = "Annual Earthquake Frequency near Tohoku, Japan - Logarithmic Scale",
       subtitle = "Three-Layer Neural Network")


#---generate plot returned to the STANDARD SCALE---
ggplot(mlp_plot, aes(x = mag, y = 10^freqc, group = type, color = type)) +
  geom_line() +
  geom_point(size = 2, shape = 17 ) +
  theme_minimal() +
  labs(x = "Magnitude",
       y = "Annual Frequency of At Least this Magnitude",
       title = "Annual Earthquake Frequency near Tohoku, Japan - Logarithmic Scale",
       subtitle = "Three-Layer Neural Network")
```


<!---   Return here with name change and code cleaning stuff after implementing the above  in Shiny  --->




### testing capacity levels and MSE measurements
```{r eval=FALSE, include=FALSE}
set.seed(4723)
#---one hidden layer---
mlp <- neuralnet(freqc ~ mag,
                 stepmax = 1e+06,
                 data = train,
                 hidden = c(5))

#predictions on test data
pps <- predict(mlp, newdata = data.frame(mag = test$mag))

#SSE to get test error
TestErr1 <- sum((pps - test$freqc)^2)
TrainErr1 <- mlp$result.matrix[1,]

set.seed(4723)
#---two hidden layers---
mlp <- neuralnet(freqc ~ mag,
                 stepmax = 1e+06,
                 data = train,
                 hidden = c(5,5))

#predictions on test data
pps <- predict(mlp, newdata = data.frame(mag = test$mag))

#SSE to get test error
TestErr2 <- sum((pps - test$freqc)^2)
TrainErr2 <- mlp$result.matrix[1,]

set.seed(4723)
#---three hidden layers---
mlp <- neuralnet(freqc ~ mag,
                 stepmax = 1e+06,
                 data = train,
                 hidden = c(5,5,5))

#predictions on test data
pps <- predict(mlp, newdata = data.frame(mag = test$mag))

#MSE to get test error
TestErr3 <- sum((pps - test$freqc)^2)
TrainErr3 <- mlp$result.matrix[1,]

#View results
TestError <- cbind(TestErr1,TestErr2,TestErr3)[1:3]
TrainError <- cbind(TrainErr1, TrainErr2, TrainErr3)[1:3]
GeneralizationGap <- TrainError - TestError

data.frame(rbind(TestError,TrainError,GeneralizationGap))
```




## brnn method

6-layer neural network that utilizes Bayesian Regularization

predictions for a magnitude 9.1 earthquake

### Building the Network
```{r}
x <- earthquakes_log$mag
y <- earthquakes_log$freqc

brnn <- brnn(y~x,neurons=6)                       # build model
summary(brnn)                                     # summary of model

#---return interval of years based on 9.1 prediction
b <- predict(brnn, newdata = data.frame(x = 9.1))
1/(10^b)
```

Using this neural network model, the expected frequency of a magnitude 9.1 earthquake would be one every `1/10^b` years.


### plots for brnn

```{r}

#---actual test data---
actual_log_brnn <- earthquakes_log %>% 
  mutate(type = "actual")
 # add_row(mag = addt, freqc = NA, type = "actual")

#---predicted data---
mdp <- seq(8,9.1, by = .1) #additional magnitude data points to add to prediction data

bnn_preds <- earthquakes_log$mag %>% append(mdp) #append additional magnitudes to make predictions

predicted_log_brnn <- data.frame(mag = bnn_preds,
                             freqc = predict(brnn, newdata = data.frame(x = bnn_preds)),
                             type = "predicted")


#---combine test and predictions for plot---
brnn_plot <- rbind(predicted_log_brnn,actual_log_brnn[,c(1,3,4)])

#---generate plot---
ggplot(brnn_plot, aes(x = mag, y = freqc, group = type, color = type)) +
  geom_line() +
  geom_point(size = 2, shape = 17 , alpha = .5) +
  theme_minimal() +
  labs(x = "Magnitude",
       y = "Annual Frequency of At Least this Magnitude",
       title = "Annual Earthquake Frequency near Tohoku, Japan - Logarithmic Scale",
       subtitle = "Three-Layer Neural Network with Bayesian Regularization")
```

Simulating 100 networks' predictions for relative magnitudes with *neurons = 6*
```{r}
n <- 1:1000
w <- NULL
f <- NULL
ddf <- actual_log_brnn[,c(1,3,4)] %>% mutate(iteration = 0)
for(i in 1:length(n)){
  c <- brnn(y~x,neurons=6)
predicted_log_brnn <- data.frame(mag = bnn_preds,
                             freqc = predict(c, newdata = data.frame(x = bnn_preds)),
                             type = "predicted",
                             iteration = i)
f[[i]] <- predicted_log_brnn
ddf <- add_row(ddf,f[[i]])
}

ggplot(ddf, aes(x = mag, y = freqc, group = iteration, shape = type, alpha = type, color = type)) +
  geom_line(show.legend = T) +
  geom_point(aes(size = type), shape = 17) +
  theme_minimal() +
  labs(x = "Magnitude",
       y = "Annual Frequency of At Least this Magnitude",
       title = "Annual Earthquake Frequency near Tohoku, Japan - Logarithmic Scale",
       subtitle = "Three-Layer Neural Network with Bayesian Regularization") +
  scale_alpha_discrete(range = c(1, .25)) +
  scale_size_discrete(range = c(2,1))

#subset all observations for a 9.1
ddf_9.1 <- ddf[which(ddf$mag == 9.1),]

ddf_9.1 <- ddf_9.1[which(ddf_9.1$freqc > -2.6),] #to remove the outlier

ggplot(ddf_9.1, aes(x = iteration, y = 1/10^(freqc))) +
geom_point(size = 2, shape = 16, color = "cyan4") + 
    labs(x = "Iteration",
         y = "Predicted Lapsed Time (Years) Between Occurrences",
         title = "Predictions for a Magnitude 9.1 Earthquake",
         subtitle = "Three-Layer Neural Network with Bayesian Regularization") +
  theme_minimal()


ggplot(ddf_9.1, aes(sample = 1/10^(freqc))) +
geom_qq() + 
    labs(x = "Iteration",
         y = "Predicted Lapsed Time (Years) Between Occurrences",
         title = "Predictions for a Magnitude 9.1 Earthquake",
         subtitle = "Three-Layer Neural Network with Bayesian Regularization") +
  theme_minimal()

#This, I believe, may just be the approximate posterior predictve distribution for a magnitude 9.1
ggplot(ddf_9.1, aes(x = 1/10^(freqc))) +
geom_density() + 
    labs(x = "Predicted Lapsed Time (Years) Between Occurrences",
         y = "Density",
         title = "Approximate Posterior Predictive Density",
         subtitle = "Three-Layer Neural Network with Bayesian Regularization") +
  theme_minimal()
```


Use this for the shiny app
```{r}

#distribution of the data for 9.1 - transformed to represent predicted lapsed time between occurrences
plot_ly(data = ddf_9.1, x = ~iteration, y = ~1/10^(freqc)) %>% 
layout(title = 'Predictions for a Magnitude 9.1 Earthquake',
   #    plot_bgcolor = "#e5ecf6",
       xaxis = list(title = 'Iteration'),
       yaxis = list(title = 'Predicted Lapsed Time Between Occurrences'))
```


### plot for brnn returned to standard scale
```{r eval=FALSE, include=FALSE}
brnn_plot2 <- brnn_plot %>% 
  mutate(freqc = 10^freqc)

ggplot(brnn_plot2, aes(x = mag, y = freqc, group = type, color = type)) +
  geom_line() +
  geom_point(size = 2, shape = 17, alpha = .5) +
  theme_minimal() +
  labs(x = "Magnitude",
       y = "Annual Frequency of At Least this Magnitude",
       title = "Annual Earthquake Frequency near Tohoku, Japan - Standard Scale",
       subtitle = "Three-Layer Neural Network with Bayesian Regularization")
```








Simulating 100 networks' predictions for magnitude 9.1 with *neurons = 6*
```{r eval=FALSE, include=FALSE}
n <- 1:100
w <- NULL
for(i in 1:length(n)){
  c <- brnn(y~x,neurons=6)
  j <- predict(c, newdata = data.frame(x = 9.1))
  w[i] <- 1/(10^j)
}

sim <- data.frame(n,w)

plot_ly(data = sim, x = ~n, y = ~w)
```












<!--
Reviewing Regularization
```{r eval=FALSE, include=FALSE}
plot(x,y,
     main="Bayesian Regularization for ANN 1-6-1")
lines(x,predict(c),col="blue",lty=2)
legend("topright",legend="Fitted model",col="blue",lty=2,bty="n")

#using ggplot:

ggplot(gg, aes(x = mag, y = freqc)) +
  geom_point(size = 4, shape = 17 ) +
  geom_line(aes(y = 10^predict(c)))
```


```{r eval=FALSE, include=FALSE}
# https://cran.r-project.org/web/packages/brnn/brnn.pdf

# What I am doing here is testing the model (on the logistic scale) using different variations of neurons to see what the predicted outcome for a 9.1 might be

x <- earthquakes_log$mag
y <- earthquakes_log$freqc
t <- seq(from = 9, to = 10, length = 10)

c <- brnn(y~x,neurons=10)

ps <- predict(c, newdata = data.frame(x = t))
ps <- 1/(10^ps)

# plot(t,ps)
# lines(t,ps,col="blue",lty=2)

#6 neurons seems to hold well for a 9.1 when simulating 100 networks

n <- 1:100
w <- NULL
for(i in 1:length(n)){
  c <- brnn(y~x,neurons=6)
  j <- predict(c, newdata = data.frame(x = 9.1))
  w[i] <- 1/(10^j)
}
```
-->


<!--

### caret method with method = brnn

```{r eval=FALSE, include=FALSE}
fitControl <- trainControl(method = "cv", number = 10)

#use gg for original data, gg2 for log scale

c <- train(freqc ~ mag, data = gg2,
      method = "brnn",
      preProc = c("center", "scale"),
#      neurons = 2,
      trControl = fitControl)

#summary(c)

p <- predict(c, newdata = data.frame(mag = 9.1))

predicts <- add_row(gg2, mag = 9.1, freq = p, freqc = p)
```

Plot of the data with new predicted point at magnitude 9.1
```{r eval=FALSE, include=FALSE}
ggplot(predicts, aes(x = mag, y = freqc)) +
  geom_point(size = 4, shape = 17 )
```

Preidicted frequency (in years) of a magnitude 9.1 earthquake
```{r eval=FALSE, include=FALSE}
1/(10^p)
```





```{r eval=FALSE, include=FALSE}
eq <- eq[c(3:3159),] #I only need the data up to that last point (for now) and only entire years up to then

ggplot(eq, aes(x = mag)) +
  geom_point(stat = "count", size = 4, shape = 17 ) + 
  scale_x_binned(nice.breaks = T,
                 n.breaks = 30)

# dd <- data.frame(cut(eq$mag, breaks = seq(from=1, to=9, by = .1) ) %>% 
#                    table)
# dd <- dd[c(35:80),]

ggplot(eq, aes(x = mag)) +
  geom_point(stat = "count", size = 4, shape = 17 ) + 
  scale_x_binned(nice.breaks = T,
                 n.breaks = 30) +
  scale_y_continuous(trans = 'log10')

```
-->

